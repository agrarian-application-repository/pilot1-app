input:

  # str: Data source (a video) for in-danger analysis.
  source: 'data/MAICH_v1/DJI_20241024104935_0008_D.MP4'

  # str: Drone metadata file (.srt)
  flight_data: 'data/MAICH_v1/DJI_20241024104935_0008_D.SRT'

  # str: Path to the DEM data
  # dem: 'data/DEM/merged/merged.tif'
  dem: 'data/DEM/Copernicus_DSM_04_N35_00_E024_00_DEM.tif'

  # str or null: Path to the DEM data mask, if null assumes all pixels are valid
  # dem_mask: 'data/DEM/merged/merged_mask.tif'
  dem_mask: null

  # float: radius of the of the safety around each sheep/goats, in meters
  safety_radius_m: 5.0

  # float: slope angle after which the portion of terrain is considered dangerous for the animals
  slope_angle_threshold: 30.0

  # set of tuples (longitude, latitude) defining the points marking the vertexes of the geofencing area
  geofencing_vertexes:
    - [ 21.2, 33.7 ]
    - [ 24.7, 35.7 ]
    - [ 24.7, 35.2 ]
    - [ 21.2, 33.2 ]

  # float: width of the camera sensor in millimeters
  drone_sensor_width_mm: 17.3 # standard for 4/3 CMOS ensor

  # float: height of the camera sensor in millimeters
  drone_sensor_height_mm: 13.0  # standard for 4/3 CMOS sensor

  # int: width of the camera sensor in pixels
  drone_sensor_width_pixels: 5184 # standard Effective 20MP for 4/3 CMOS sensor

  # int: height of the camera sensor in pixels
  drone_sensor_height_pixels: 3888  # standard Effective 20MP for 4/3 CMOS sensor

  # int : Video height for in-danger analysis. If null, use original data height
  # Range: Any positive integer.
  height: null

  # int : Video width for in-danger analysis. If null, use original data width
  # Range: Any positive integer.
  width: null

  # int: Frame stride for video inputs.
  # Allows skipping frames to speed up inference. Higher values skip more frames.
  # Range: Any positive integer.
  vid_stride: 1

######################################################################################################################

output:

  # str: Name of the directory where the results of the analysis will be saved
  output_dir: 'experiments/test_in_danger_v2'

  # str: Whether to save processed videos of not
  save_videos: true

  # str: Name of the files on which alerts will be saved
  alert_file_name: 'alerts'

  # int: Minimum number of seconds between alerts
  alerts_cooldown_seconds: 1

  # str: Name of the video showing the annotated original data (with/without sheep count and tracks)
  annotated_video_name: 'in_danger_annotated'

  # bool: show sheep count on the annotated video
  draw_count: true

######################################################################################################################

detection:

  # str: Path to the detection model checkpoint file (required).
  # Specifies the .pt file for the model to be used during tracking.
  model_checkpoint: 'experiments/for_maich/weights/best.pt'

  # float: Confidence threshold for detection filtering.
  # Detections with a confidence score below this value will be discarded.
  # Range: 0.0 to 1.0
  conf: 0.3

  # float: IoU threshold for detection Non-Maximum Suppression (NMS).
  # Helps reduce duplicate detections by suppressing overlapping boxes.
  # Range: 0.0 to 1.0
  iou: 0.7

  # bool: Enable half-precision (FP16) inference.
  # Can increase inference speed on supported GPUs with minimal accuracy loss.
  half: false

  # str: Device for processing (e.g., cpu, cuda:0).
  # Specifies whether to use CPU or a particular GPU for inference.
  device: 3

  # int: Maximum number of detections per image.
  # Limits the total number of objects that can be detected in a single image.
  # Range: Any positive integer.
  max_det: 300

  # list[int]: Filter detections by specific class IDs for the detector model.
  # Only predictions belonging to the specified class IDs will be returned.
  classes: null

  # bool: Enable test-time augmentation (TTA) during tracking.
  # Improves detection robustness by augmenting inputs, at the cost of slower inference.
  augment: false

  # bool: Enable class-agnostic Non-Maximum Suppression (NMS).
  # Treats all classes equally during NMS, merging overlapping boxes regardless of class.
  agnostic_nms: false

######################################################################################################################

segmentation:

  # str: Path to the detetcion model checkpoint file (required).
  # Specifies the .pt file for the model to be used during tracking.
  model_checkpoint: 'yolo11m-seg.pt'

  # bool: Enable half-precision (FP16) inference.
  # Can increase inference speed on supported GPUs with minimal accuracy loss.
  half: false

  # str: Device for processing (e.g., cpu, cuda:0).
  # Specifies whether to use CPU or a particular GPU for inference.
  device: 3

  # list[int]: Filter detections by specific class IDs for the segmentation model.
  # Only masks for the specified class IDs will be returned.
  classes: [2] # car

  # bool: Enable test-time augmentation (TTA) during tracking.
  # Improves detection robustness by augmenting inputs, at the cost of slower inference.
  augment: false

  # bool: Use high-resolution segmentation masks if available.
  # Provides higher quality segmentation outputs when supported by the model.
  retina_masks: false





